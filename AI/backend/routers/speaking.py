"""
Speaking Router - Korean speaking practice and pronunciation evaluation
TÃ­ch há»£p model pronunciation check vá»›i GPT Ä‘á»ƒ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao vÃ  tráº£i nghiá»‡m tá»‘t
"""
from fastapi import APIRouter, HTTPException, UploadFile, File, Form
from models.schemas import (
    ReadAloudResponse, 
    AccuracyDetails, 
    FreeSpeakResponse,
    PronunciationFeedback,
    PhonemeDetail,
    WordFeedback,
    PronunciationFeedbackSummary
)
from services import openai_service, accuracy_service
from services.tts_service import generate_speech
from services.stt_service import transcribe_audio_cheap  # Use local Whisper (FREE)
from services.pronunciation_model_service import (
    check_pronunciation_from_bytes,
    is_model_loaded
)
from services.error_handlers import handle_openai_error
import logging
from typing import Optional, Dict, Any, Tuple, List
from pathlib import Path

logger = logging.getLogger(__name__)

router = APIRouter(
    prefix="/api",
    tags=["speaking"]
)

# Model is loaded in main.py startup event
# Just check if it's available
def get_model_status() -> bool:
    """Check if pronunciation model is loaded"""
    return is_model_loaded()


def _classify_phoneme(phoneme: str) -> str:
    """PhÃ¢n loáº¡i phoneme: initial (phá»¥ Ã¢m Ä‘áº§u), vowel (nguyÃªn Ã¢m), final (phá»¥ Ã¢m cuá»‘i)"""
    from services.pronunciation_model_service import LEADS, VOWELS, TAILS
    
    if phoneme in LEADS:
        return "initial"  # Phá»¥ Ã¢m Ä‘áº§u
    elif phoneme in VOWELS:
        return "vowel"  # NguyÃªn Ã¢m
    elif phoneme in TAILS:
        return "final"  # Phá»¥ Ã¢m cuá»‘i
    else:
        return "other"


def _generate_local_feedback_vi(
    expected_text: str,
    spoken_text: str,
    phoneme_accuracy: Optional[float] = None,
    word_accuracy: Optional[float] = None,
    model_result: Optional[Dict[str, Any]] = None,
    accuracy_details: Optional[Dict[str, Any]] = None
) -> Tuple[str, List[str]]:
    """
    Táº¡o feedback báº±ng tiáº¿ng Viá»‡t tá»« pronunciation model results (KHÃ”NG dÃ¹ng GPT)
    
    Args:
        expected_text: VÄƒn báº£n Ä‘Ãºng
        spoken_text: VÄƒn báº£n ngÆ°á»i dÃ¹ng Ä‘Ã£ nÃ³i
        phoneme_accuracy: Äá»™ chÃ­nh xÃ¡c á»Ÿ má»©c phoneme (0-100)
        word_accuracy: Äá»™ chÃ­nh xÃ¡c á»Ÿ má»©c tá»« (0-100)
        model_result: Káº¿t quáº£ tá»« pronunciation model
        accuracy_details: Chi tiáº¿t tá»« accuracy service
    
    Returns:
        tuple: (feedback_vi, tricky_words)
    """
    feedback_parts = []
    tricky_words = []
    
    # XÃ¡c Ä‘á»‹nh overall score
    overall_score = phoneme_accuracy if phoneme_accuracy is not None else word_accuracy
    
    if overall_score is None:
        overall_score = 0.0
    
    # Overall assessment báº±ng tiáº¿ng Viá»‡t
    if overall_score >= 95:
        feedback_parts.append("ðŸŽ‰ Tuyá»‡t vá»i! PhÃ¡t Ã¢m cá»§a báº¡n gáº§n nhÆ° hoÃ n háº£o!")
    elif overall_score >= 85:
        feedback_parts.append("ðŸ‘ LÃ m tá»‘t láº¯m! PhÃ¡t Ã¢m cá»§a báº¡n ráº¥t tá»‘t.")
    elif overall_score >= 70:
        feedback_parts.append("âœ… Cá»‘ gáº¯ng tá»‘t! Báº¡n Ä‘ang Ä‘i Ä‘Ãºng hÆ°á»›ng.")
    elif overall_score >= 50:
        feedback_parts.append("ðŸ’ª Tiáº¿p tá»¥c luyá»‡n táº­p! Báº¡n Ä‘ang tiáº¿n bá»™.")
    else:
        feedback_parts.append("ðŸ”„ HÃ£y thá»­ láº¡i. Äá»«ng lo, luyá»‡n táº­p sáº½ giÃºp báº¡n cáº£i thiá»‡n!")
    
    # Chi tiáº¿t tá»« pronunciation model (náº¿u cÃ³)
    if model_result:
        wrong_phonemes = model_result.get("wrong_phonemes", [])
        wrong_words = model_result.get("wrong_words", [])
        substitutions = model_result.get("substitutions", 0)
        deletions = model_result.get("deletions", 0)
        insertions = model_result.get("insertions", 0)
        
        if phoneme_accuracy is not None:
            feedback_parts.append(f"Äá»™ chÃ­nh xÃ¡c phoneme: {phoneme_accuracy:.1f}%.")
        
        if wrong_phonemes:
            tricky_phonemes = list(set([exp for exp, pred in wrong_phonemes[:5]]))
            feedback_parts.append(f"PhÃ¡t Ã¢m cáº§n cáº£i thiá»‡n: {', '.join(tricky_phonemes[:3])}.")
        
        if wrong_words:
            tricky_words = list(set(wrong_words[:5]))
            feedback_parts.append(f"CÃ¡c tá»« cáº§n luyá»‡n táº­p: {', '.join(tricky_words[:3])}.")
        
        if substitutions > 0:
            feedback_parts.append(f"CÃ³ {substitutions} phoneme bá»‹ thay tháº¿ sai.")
        if deletions > 0:
            feedback_parts.append(f"CÃ³ {deletions} phoneme bá»‹ thiáº¿u.")
        if insertions > 0:
            feedback_parts.append(f"CÃ³ {insertions} phoneme thá»«a.")
    
    # Chi tiáº¿t tá»« word accuracy (náº¿u khÃ´ng cÃ³ model result)
    elif accuracy_details:
        matches = accuracy_details.get("matches", 0)
        substitutions = accuracy_details.get("substitutions", 0)
        deletions = accuracy_details.get("deletions", 0)
        insertions = accuracy_details.get("insertions", 0)
        
        issues = []
        if deletions > 0:
            issues.append(f"{deletions} tá»« bá»‹ thiáº¿u")
        if substitutions > 0:
            issues.append(f"{substitutions} tá»« bá»‹ sai")
        if insertions > 0:
            issues.append(f"{insertions} tá»« thá»«a")
        
        if issues:
            feedback_parts.append(f"CÃ¡c váº¥n Ä‘á»: {', '.join(issues)}.")
        
        if matches > 0:
            feedback_parts.append(f"Báº¡n Ä‘Ã£ phÃ¡t Ã¢m Ä‘Ãºng {matches} tá»«!")
    
    feedback_text = " ".join(feedback_parts)
    return feedback_text, tricky_words


def _build_pronunciation_feedback(
    pronunciation_result,
    expected_text: str
) -> Optional[PronunciationFeedback]:
    """Táº¡o pronunciation_feedback chi tiáº¿t tá»« pronunciation_result"""
    try:
        from services.pronunciation_model_service import LEADS, VOWELS, TAILS
        
        # Táº¡o phoneme_details
        phoneme_details = []
        expected_phonemes = pronunciation_result.expected_phonemes
        predicted_phonemes = pronunciation_result.predicted_phonemes
        
        # Táº¡o map cá»§a wrong phonemes Ä‘á»ƒ dá»… tra cá»©u
        wrong_phoneme_map = {}
        for exp, pred in pronunciation_result.wrong_phonemes:
            # TÃ¬m vá»‹ trÃ­ cá»§a wrong phoneme trong expected_phonemes
            for idx, exp_phn in enumerate(expected_phonemes):
                if exp_phn == exp and idx not in wrong_phoneme_map:
                    wrong_phoneme_map[idx] = pred
                    break
        
        # Xá»­ lÃ½ tá»«ng phoneme expected
        max_len = max(len(expected_phonemes), len(predicted_phonemes))
        for i in range(max_len):
            exp_phn = expected_phonemes[i] if i < len(expected_phonemes) else None
            pred_phn = predicted_phonemes[i] if i < len(predicted_phonemes) else None
            
            if exp_phn is None:
                # Insertion - phoneme thá»«a
                phoneme_details.append(PhonemeDetail(
                    position=i,
                    expected="",
                    predicted=pred_phn,
                    type=_classify_phoneme(pred_phn) if pred_phn else "other",
                    is_correct=False,
                    is_extra=True
                ))
            elif pred_phn is None:
                # Deletion - phoneme thiáº¿u
                phoneme_details.append(PhonemeDetail(
                    position=i,
                    expected=exp_phn,
                    predicted="",
                    type=_classify_phoneme(exp_phn),
                    is_correct=False,
                    is_missing=True
                ))
            else:
                # So sÃ¡nh expected vs predicted
                is_correct = exp_phn == pred_phn
                # Náº¿u khÃ´ng Ä‘Ãºng, cÃ³ thá»ƒ lÃ  substitution
                if not is_correct and i in wrong_phoneme_map:
                    pred_phn = wrong_phoneme_map[i]
                
                phoneme_details.append(PhonemeDetail(
                    position=i,
                    expected=exp_phn,
                    predicted=pred_phn,
                    type=_classify_phoneme(exp_phn),
                    is_correct=is_correct
                ))
        
        # PhÃ¢n tÃ­ch tá»«ng tá»« vá»›i phoneme details
        word_feedback_list = []
        words = expected_text.split()
        
        # Map phonemes to words (simplified - má»—i tá»« cÃ³ ~3 phonemes: initial, vowel, final)
        phoneme_idx = 0
        for word_idx, word in enumerate(words):
            # Æ¯á»›c tÃ­nh sá»‘ phoneme trong tá»« nÃ y (má»—i kÃ½ tá»± Hangul = 2-3 phonemes)
            word_phoneme_count = len(word) * 2  # Æ¯á»›c tÃ­nh
            word_phonemes = []
            
            for i in range(min(word_phoneme_count, len(phoneme_details) - phoneme_idx)):
                if phoneme_idx + i < len(phoneme_details):
                    phn_detail = phoneme_details[phoneme_idx + i]
                    word_phonemes.append(phn_detail)
            
            # TÃ­nh accuracy cho tá»« nÃ y
            if word_phonemes:
                correct_count = sum(1 for p in word_phonemes if p.is_correct)
                word_accuracy = (correct_count / len(word_phonemes)) * 100
            else:
                word_accuracy = 0
            
            word_feedback_list.append(WordFeedback(
                word=word,
                position=word_idx,
                phonemes=word_phonemes,
                accuracy=round(word_accuracy, 1),
                is_correct=word_accuracy >= 80  # Threshold 80%
            ))
            
            phoneme_idx += len(word_phonemes)
        
        # Táº¡o wrong_phonemes vá»›i feedback
        wrong_phonemes_list = []
        for i, (exp, pred) in enumerate(pronunciation_result.wrong_phonemes):
            wrong_phonemes_list.append({
                "expected": exp,
                "predicted": pred,
                "position": i,
                "type": _classify_phoneme(exp),
                "is_correct": False,
                "feedback": f"PhÃ¡t Ã¢m '{exp}' thÃ nh '{pred}'. Cáº§n luyá»‡n táº­p {'phá»¥ Ã¢m Ä‘áº§u' if _classify_phoneme(exp) == 'initial' else 'nguyÃªn Ã¢m' if _classify_phoneme(exp) == 'vowel' else 'phá»¥ Ã¢m cuá»‘i'}."
            })
        
        # Táº¡o summary
        summary = PronunciationFeedbackSummary(
            total_phonemes=len(expected_phonemes),
            correct_phonemes=pronunciation_result.matches,
            wrong_phonemes=pronunciation_result.substitutions,
            missing_phonemes=pronunciation_result.deletions,
            extra_phonemes=pronunciation_result.insertions,
            initial_errors=sum(1 for p in phoneme_details if p.type == "initial" and not p.is_correct),
            vowel_errors=sum(1 for p in phoneme_details if p.type == "vowel" and not p.is_correct),
            final_errors=sum(1 for p in phoneme_details if p.type == "final" and not p.is_correct)
        )
        
        return PronunciationFeedback(
            phoneme_accuracy=pronunciation_result.phoneme_accuracy,
            per=pronunciation_result.per,
            phoneme_details=phoneme_details,
            word_feedback=word_feedback_list,
            wrong_phonemes=wrong_phonemes_list,
            expected_phonemes=expected_phonemes,
            predicted_phonemes=predicted_phonemes,
            wrong_words=pronunciation_result.wrong_words,
            matches=pronunciation_result.matches,
            substitutions=pronunciation_result.substitutions,
            insertions=pronunciation_result.insertions,
            deletions=pronunciation_result.deletions,
            summary=summary
        )
    except Exception as e:
        logger.error(f"Error building pronunciation feedback: {e}")
        return None


@router.post("/speaking/read-aloud", response_model=ReadAloudResponse)
async def check_read_aloud(
    audio: UploadFile = File(..., description="Audio file (webm, mp3, wav)"),
    expected_text: str = Form(..., description="The Korean text the user should read"),
    language: str = Form(default="ko", description="Language code (ko for Korean)")
):
    """
    ÄÃ¡nh giÃ¡ phÃ¡t Ã¢m tiáº¿ng HÃ n khi Ä‘á»c to
    Sá»­ dá»¥ng LOCAL models - KHÃ”NG dÃ¹ng OpenAI API
    
    FLOW:
    =====
    1. NgÆ°á»i dÃ¹ng báº¥m mic â†’ ghi Ã¢m (5 giÃ¢y) â†’ file .m4a
    2. Flutter gá»­i file audio lÃªn backend (FastAPI/Python)
    3. Backend xá»­ lÃ½:
       a. â­ PHáº¦N CHÃNH - DÃ¹ng pronunciation_model.pt Ä‘á»ƒ tÃ­nh Ä‘iá»ƒm:
          - Audio â†’ Wav2Vec2 features â†’ Conformer model â†’ predicted_phonemes
          - expected_text â†’ hangul_g2p() â†’ expected_phonemes
          - So sÃ¡nh predicted_phonemes vs expected_phonemes â†’ tÃ­nh Ä‘iá»ƒm + tÃ¬m lá»—i
          - ÄÃ‚Y LÃ€ CÃCH TÃNH ÄIá»‚M PHÃT Ã‚M - KHÃ”NG Cáº¦N TRANSCRIPT!
       
       b. (OPTIONAL) DÃ¹ng LOCAL Whisper â†’ chuyá»ƒn audio thÃ nh text (transcript)
          - Chá»‰ Ä‘á»ƒ hiá»ƒn thá»‹ cho user biáº¿t há» nÃ³i gÃ¬
          - TÃ­nh word accuracy (bá»• sung, KHÃ”NG pháº£i Ä‘iá»ƒm chÃ­nh)
          - Náº¿u Whisper fail, váº«n tÃ­nh Ä‘Æ°á»£c Ä‘iá»ƒm tá»« pronunciation model
       
    4. Tráº£ vá» JSON vá»›i:
       - overall_score: Ä‘iá»ƒm tá»•ng (tá»« phoneme_accuracy - Ä‘iá»ƒm chÃ­nh)
       - phoneme_accuracy: Ä‘á»™ chÃ­nh xÃ¡c phoneme (tá»« pronunciation_model.pt)
       - pronunciation_feedback: chi tiáº¿t tá»«ng phoneme, tá»«ng tá»«
       - transcript: text ngÆ°á»i dÃ¹ng Ä‘Ã£ nÃ³i (optional, chá»‰ Ä‘á»ƒ hiá»ƒn thá»‹)
    5. Flutter nháº­n JSON â†’ váº½ giao diá»‡n Ä‘áº¹p (highlight lá»—i, vÃ²ng trÃ²n Ä‘iá»ƒm, animation)

    Supported audio formats: webm, mp3, wav, m4a
    """
    try:
        logger.info(f"Read-aloud check - Expected: '{expected_text[:50]}...', Audio: {audio.filename}")

        # ============================================
        # STEP 1: Transcribe audio â†’ Text (OPTIONAL - chá»‰ Ä‘á»ƒ hiá»ƒn thá»‹)
        # ============================================
        # âš ï¸ QUAN TRá»ŒNG: Transcript KHÃ”NG Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ tÃ­nh Ä‘iá»ƒm phÃ¡t Ã¢m!
        # 
        # Äiá»ƒm phÃ¡t Ã¢m Ä‘Æ°á»£c tÃ­nh HOÃ€N TOÃ€N tá»« pronunciation_model.pt:
        # - Audio â†’ pronunciation_model.pt â†’ predicted phonemes
        # - expected_text â†’ hangul_g2p() â†’ expected phonemes  
        # - So sÃ¡nh predicted vs expected â†’ Ä‘iá»ƒm
        #
        # Transcript chá»‰ Ä‘á»ƒ:
        # - Hiá»ƒn thá»‹ cho user biáº¿t há» nÃ³i gÃ¬ (UI feedback)
        # - TÃ­nh word accuracy (bá»• sung, KHÃ”NG pháº£i Ä‘iá»ƒm chÃ­nh)
        transcript = ""
        try:
            transcript = await transcribe_audio_cheap(
                file=audio,
                language=language
            )
            logger.info(f"âœ… Transcript (ngÆ°á»i dÃ¹ng nÃ³i): '{transcript}'")
        except Exception as e:
            logger.warning(f"âš ï¸ Transcript failed (KHÃ”NG áº£nh hÆ°á»Ÿng Ä‘iá»ƒm phÃ¡t Ã¢m): {e}")
            # Transcript khÃ´ng báº¯t buá»™c, tiáº¿p tá»¥c vá»›i pronunciation model

        # ============================================
        # STEP 2: DÃ¹ng pronunciation_model.pt â†’ Dá»± Ä‘oÃ¡n phoneme (PHáº¦N CHÃNH - TÃNH ÄIá»‚M)
        # ============================================
        # â­ ÄÃ‚Y LÃ€ PHáº¦N QUAN TRá»ŒNG NHáº¤T - TÃ­nh Ä‘iá»ƒm phÃ¡t Ã¢m:
        # 
        # Flow tÃ­nh Ä‘iá»ƒm:
        # 1. Audio â†’ Wav2Vec2 features (extract acoustic features tá»« audio)
        # 2. pronunciation_model.pt (Conformer) â†’ dá»± Ä‘oÃ¡n chuá»—i phoneme tá»« audio
        #    â†’ predicted_phonemes = ["ã…‡", "ã…", "ã„´", ...] (tá»« audio trá»±c tiáº¿p)
        # 3. expected_text â†’ hangul_g2p() â†’ phoneme chuáº©n
        #    â†’ expected_phonemes = ["ã…‡", "ã…", "ã„´", ...] (tá»« text)
        # 4. So sÃ¡nh predicted_phonemes vs expected_phonemes â†’ tÃ­nh Ä‘iá»ƒm + tÃ¬m lá»—i
        # 
        # âš ï¸ KHÃ”NG Cáº¦N TRANSCRIPT - Model tá»± dá»± Ä‘oÃ¡n phonemes tá»« audio!
        # Transcript chá»‰ Ä‘á»ƒ hiá»ƒn thá»‹, khÃ´ng áº£nh hÆ°á»Ÿng Ä‘iá»ƒm phÃ¡t Ã¢m
        model_result = None
        phoneme_accuracy = None
        per = None
        pronunciation_result = None
        pronunciation_feedback_obj = None
        
        if get_model_status():
            try:
                # Äá»c audio bytes tá»« file Ä‘Ã£ upload
                audio_bytes = await audio.read()
                await audio.seek(0)  # Reset file pointer Ä‘á»ƒ cÃ³ thá»ƒ dÃ¹ng láº¡i
                
                # Gá»i pronunciation model Ä‘á»ƒ dá»± Ä‘oÃ¡n phoneme vÃ  so sÃ¡nh
                pronunciation_result = check_pronunciation_from_bytes(
                    audio_bytes=audio_bytes,
                    expected_text=expected_text,  # Text chuáº©n Ä‘á»ƒ táº¡o phoneme chuáº©n
                    sample_rate=16000,
                    audio_format=Path(audio.filename).suffix[1:] if audio.filename else "wav"
                )
                
                if pronunciation_result:
                    # LÆ°u káº¿t quáº£ tá»« model
                    model_result = {
                        "phoneme_accuracy": pronunciation_result.phoneme_accuracy,
                        "per": pronunciation_result.per,
                        "wrong_phonemes": pronunciation_result.wrong_phonemes,
                        "wrong_words": pronunciation_result.wrong_words,
                        "matches": pronunciation_result.matches,
                        "substitutions": pronunciation_result.substitutions,
                        "insertions": pronunciation_result.insertions,
                        "deletions": pronunciation_result.deletions
                    }
                    phoneme_accuracy = pronunciation_result.phoneme_accuracy
                    per = pronunciation_result.per
                    logger.info(f"âœ… Pronunciation model check: {phoneme_accuracy:.1f}% accuracy, PER: {per:.4f}")
                    
                    # Táº¡o pronunciation_feedback chi tiáº¿t (tá»«ng phoneme, tá»«ng tá»«)
                    pronunciation_feedback_obj = _build_pronunciation_feedback(
                        pronunciation_result=pronunciation_result,
                        expected_text=expected_text
                    )
                else:
                    logger.warning("âš ï¸ Model check returned None, falling back to word accuracy")
            except Exception as e:
                logger.error(f"âŒ Error in pronunciation model check: {e}. Falling back to word accuracy.", exc_info=True)
        
        # ============================================
        # STEP 3: TÃ­nh word-level accuracy (Bá»” SUNG - khÃ´ng pháº£i Ä‘iá»ƒm chÃ­nh)
        # ============================================
        # So sÃ¡nh transcript (ngÆ°á»i dÃ¹ng nÃ³i) vs expected_text (chuáº©n)
        # âš ï¸ LÆ¯U Ã: Äiá»ƒm chÃ­nh lÃ  phoneme_accuracy tá»« model, khÃ´ng pháº£i word_accuracy
        # Word accuracy chá»‰ Ä‘á»ƒ bá»• sung thÃ´ng tin, khÃ´ng áº£nh hÆ°á»Ÿng overall_score
        word_accuracy = 0.0
        details = {}
        if transcript:
            try:
                word_accuracy, details = accuracy_service.calculate_word_accuracy(
                    expected_text=expected_text,
                    spoken_text=transcript,
                    ignore_fillers=True
                )
                logger.info(f"âœ… Word accuracy (bá»• sung): {word_accuracy}%")
            except Exception as e:
                logger.warning(f"âš ï¸ Word accuracy calculation failed: {e} (khÃ´ng áº£nh hÆ°á»Ÿng Ä‘iá»ƒm chÃ­nh)")
                # KhÃ´ng áº£nh hÆ°á»Ÿng Ä‘iá»ƒm phÃ¡t Ã¢m

        # ============================================
        # STEP 4: Táº¡o feedback báº±ng tiáº¿ng Viá»‡t (LOCAL, khÃ´ng dÃ¹ng GPT)
        # ============================================
        feedback_vi, tricky_words = _generate_local_feedback_vi(
            expected_text=expected_text,
            spoken_text=transcript,
            phoneme_accuracy=phoneme_accuracy,
            word_accuracy=word_accuracy,
            model_result=model_result,
            accuracy_details=details
        )
        logger.info(f"Feedback tiáº¿ng Viá»‡t (local): '{feedback_vi[:50]}...'")

        # Step 5: Generate TTS cho feedback (optional - won't fail if error)
        tts_vi_path = await generate_speech(
            text=feedback_vi,
            lang="vi",  # Vietnamese feedback
            allow_failure=True  # Don't fail the whole request if TTS fails
        )
        tts_vi_url = f"/media/{Path(tts_vi_path).name}" if tts_vi_path else None
        if tts_vi_url:
            logger.info(f"VI TTS generated: {tts_vi_url}")

        # Step 6: Calculate overall score
        # Æ¯u tiÃªn model score náº¿u cÃ³, náº¿u khÃ´ng dÃ¹ng word accuracy
        if phoneme_accuracy is not None:
            # Model cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n, dÃ¹ng lÃ m chÃ­nh
            overall_score = phoneme_accuracy
            logger.info(f"Using model phoneme accuracy as overall score: {overall_score:.1f}%")
        else:
            # Fallback: dÃ¹ng word accuracy
            overall_score = word_accuracy
            logger.info(f"Using word accuracy as overall score: {overall_score:.1f}%")

        # Determine emotion tag
        if overall_score >= 85:
            emotion_tag = "praise"
        elif overall_score >= 70:
            emotion_tag = "encouraging"
        else:
            emotion_tag = "corrective"

        # Build accuracy details
        # Náº¿u cÃ³ model result, Æ°u tiÃªn dÃ¹ng thÃ´ng tin tá»« model
        if model_result:
            accuracy_details_obj = AccuracyDetails(
                word_accuracy=phoneme_accuracy,  # DÃ¹ng phoneme accuracy tá»« model
                wer=per,  # DÃ¹ng PER tá»« model
                matches=model_result.get("matches", 0),
                substitutions=model_result.get("substitutions", 0),
                insertions=model_result.get("insertions", 0),
                deletions=model_result.get("deletions", 0),
                expected_words=details.get("expected_words", []),  # Giá»¯ word list tá»« accuracy service
                spoken_words=details.get("spoken_words", [])
            )
        else:
            accuracy_details_obj = AccuracyDetails(
                word_accuracy=word_accuracy,
                wer=details.get("wer", 1.0),
                matches=details.get("matches", 0),
                substitutions=details.get("substitutions", 0),
                insertions=details.get("insertions", 0),
                deletions=details.get("deletions", 0),
                expected_words=details.get("expected_words", []),
                spoken_words=details.get("spoken_words", [])
            )

        # ============================================
        # STEP 5: Tráº£ vá» JSON response
        # ============================================
        # JSON nÃ y sáº½ Ä‘Æ°á»£c Flutter nháº­n Ä‘á»ƒ váº½ giao diá»‡n:
        # - overall_score: Ä‘iá»ƒm tá»•ng (váº½ vÃ²ng trÃ²n Ä‘iá»ƒm)
        # - pronunciation_feedback: chi tiáº¿t tá»«ng phoneme (highlight lá»—i)
        # - transcript: text ngÆ°á»i dÃ¹ng Ä‘Ã£ nÃ³i
        # - feedback_vi: feedback báº±ng tiáº¿ng Viá»‡t
        ai_feedback_combined = feedback_vi

        logger.info(f"âœ… Returning response - Overall score: {overall_score:.1f}%, Phoneme accuracy: {phoneme_accuracy}%")
        return ReadAloudResponse(
            transcript=transcript,
            expected_text=expected_text,
            word_accuracy=word_accuracy,
            ai_feedback=ai_feedback_combined,  # Legacy field
            overall_score=overall_score,
            emotion_tag=emotion_tag,
            accuracy_details=accuracy_details_obj,
            feedback_en="",  # KhÃ´ng dÃ¹ng ná»¯a, Ä‘á»ƒ trá»‘ng
            feedback_vi=feedback_vi,
            tts_en_url=None,  # KhÃ´ng dÃ¹ng ná»¯a
            tts_vi_url=tts_vi_url,
            tricky_words=tricky_words,
            tts_url=None,
            pronunciation_feedback=pronunciation_feedback_obj  # Chi tiáº¿t tá»«ng phoneme, tá»«ng tá»«
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in check_read_aloud: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Lá»—i khi Ä‘Ã¡nh giÃ¡ phÃ¡t Ã¢m: {str(e)}"
        )


@router.get("/speaking/phrases")
async def get_korean_phrases(
    category: Optional[str] = None,
    difficulty: Optional[str] = None
):
    """
    Get Korean phrases and terms for pronunciation practice
    
    Args:
        category: Filter by category (greetings, food, etc.)
        difficulty: Filter by difficulty (beginner, intermediate, advanced)
    
    Returns:
        List of Korean phrases organized by category
    """
    try:
        import json
        from pathlib import Path
        
        phrases_file = Path("models/korean_phrases.json")
        if not phrases_file.exists():
            logger.warning("Korean phrases file not found")
            return {
                "categories": {},
                "difficulty_levels": {},
                "message": "Phrases file not found"
            }
        
        with open(phrases_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Filter by category if provided
        if category:
            if category in data.get("categories", {}):
                return {
                    "category": category,
                    "name": data["categories"][category]["name"],
                    "phrases": data["categories"][category]["phrases"]
                }
            else:
                raise HTTPException(
                    status_code=404,
                    detail=f"Category '{category}' not found"
                )
        
        # Filter by difficulty if provided
        if difficulty:
            if difficulty in data.get("difficulty_levels", {}):
                level_data = data["difficulty_levels"][difficulty]
                categories = level_data.get("categories", [])
                filtered_categories = {
                    cat: data["categories"][cat]
                    for cat in categories
                    if cat in data.get("categories", {})
                }
                return {
                    "difficulty": difficulty,
                    "description": level_data.get("description", ""),
                    "categories": filtered_categories
                }
            else:
                raise HTTPException(
                    status_code=404,
                    detail=f"Difficulty level '{difficulty}' not found"
                )
        
        # Return all data
        return data
        
    except json.JSONDecodeError as e:
        logger.error(f"Error parsing phrases JSON: {e}")
        raise HTTPException(
            status_code=500,
            detail="Error reading phrases file"
        )
    except Exception as e:
        logger.error(f"Error getting phrases: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error getting phrases: {str(e)}"
        )


@router.get("/speaking/model-status")
async def get_model_status_endpoint():
    """
    Check if pronunciation model is loaded and ready
    
    Returns:
        Status information about the pronunciation model
    """
    try:
        # Check current status
        model_loaded = get_model_status()
        logger.info(f"Model status check - loaded: {model_loaded}")
        
        # If not loaded, try to load it
        if not model_loaded:
            logger.info("Model not loaded, attempting to load...")
            from services.pronunciation_model_service import load_pronunciation_model
            try:
                loaded = load_pronunciation_model()
                if loaded:
                    logger.info("âœ… Model loaded successfully on demand")
                    model_loaded = True
                else:
                    logger.warning("âš ï¸ Failed to load model on demand")
                    # Check if files exist
                    from pathlib import Path
                    model_path = Path("models/pronunciation_model.pt")
                    p2id_path = Path("models/p2id.json")
                    stats_path = Path("models/wav2vec2_stats.npy")
                    
                    files_exist = {
                        "model_file": model_path.exists(),
                        "p2id_file": p2id_path.exists(),
                        "stats_file": stats_path.exists()
                    }
                    logger.info(f"Model files status: {files_exist}")
            except Exception as load_error:
                logger.error(f"Error loading model on demand: {load_error}", exc_info=True)
        
        # Double check after loading attempt
        model_loaded = get_model_status()
        
        return {
            "model_loaded": model_loaded,
            "status": "ready" if model_loaded else "not_available",
            "message": "Pronunciation model is loaded and ready" if model_loaded else "Pronunciation model not available. Will use word-level accuracy only.",
            "available": model_loaded  # Alias for frontend compatibility
        }
    except Exception as e:
        logger.error(f"Error checking model status: {e}", exc_info=True)
        return {
            "model_loaded": False,
            "status": "error",
            "message": f"Error checking model status: {str(e)}",
            "available": False
        }


@router.post("/speaking/free-speak", response_model=FreeSpeakResponse)
async def check_free_speaking(
    audio: UploadFile = File(..., description="Audio file"),
    context: Optional[str] = Form(default=None, description="Conversation context"),
    language: str = Form(default="ko", description="Language code (ko for Korean)"),
    history: Optional[str] = Form(default=None, description="JSON array of conversation history for context")
):
    """
    Free-form Korean speaking practice vá»›i Coach Ivy - Cuá»™c há»™i thoáº¡i tá»± nhiÃªn
    
    Flow:
    1. User nÃ³i â†’ Whisper (STT) â†’ Text
    2. Text â†’ GPT â†’ Pháº£n há»“i báº±ng tiáº¿ng HÃ n (nhÆ° má»™t cuá»™c há»™i thoáº¡i)
    3. Pháº£n há»“i text â†’ TTS â†’ Speech Ä‘á»ƒ user nghe Ä‘Æ°á»£c
    
    This endpoint allows natural conversation in Korean.
    GPT will respond in Korean like a real conversation partner.
    """
    try:
        logger.info(f"Free-speak request - Audio: {audio.filename}, Language: {language}")
        
        # Step 1: Transcribe user's speech using LOCAL Whisper (FREE, khÃ´ng tá»‘n quota)
        # Fallback to OpenAI Whisper only if local fails
        transcript = await transcribe_audio_cheap(
            file=audio,
            language=language
        )
        logger.info(f"User said: '{transcript}'")

        if not transcript.strip():
            raise HTTPException(
                status_code=400,
                detail="Could not transcribe audio. Please try speaking again."
            )

        # Step 2: Parse conversation history if provided (for context)
        conversation_context = None
        if history:
            try:
                import json
                history_messages = json.loads(history)
                if history_messages:
                    # Build context from history
                    conversation_context = {
                        "type": "speaking_practice",
                        "history": history_messages[-5:],  # Last 5 messages for context
                        "context": context
                    }
            except json.JSONDecodeError:
                logger.warning("Invalid history JSON, continuing without history")

        # Step 3: Check pronunciation vá»›i model (náº¿u cÃ³) - giá»‘ng live_talk
        pronunciation_result = None
        pronunciation_feedback = None
        pronunciation_accuracy = None
        
        if get_model_status():
            try:
                # Äá»c audio bytes
                audio_bytes = await audio.read()
                await audio.seek(0)  # Reset file pointer
                
                # Check pronunciation vá»›i model
                pronunciation_result = check_pronunciation_from_bytes(
                    audio_bytes=audio_bytes,
                    expected_text=transcript,  # So sÃ¡nh vá»›i transcript tá»« STT
                    sample_rate=16000,
                    audio_format=Path(audio.filename).suffix[1:] if audio.filename else "wav"
                )
                
                if pronunciation_result:
                    pronunciation_accuracy = pronunciation_result.phoneme_accuracy
                    
                    # Táº¡o pháº£n há»“i chi tiáº¿t vá» tá»«ng phoneme (phá»¥ Ã¢m, nguyÃªn Ã¢m, nguyÃªn Ã¢m cuá»‘i)
                    from services.pronunciation_model_service import LEADS, VOWELS, TAILS
                    
                    # PhÃ¢n loáº¡i phoneme thÃ nh phá»¥ Ã¢m, nguyÃªn Ã¢m, nguyÃªn Ã¢m cuá»‘i
                    def classify_phoneme(phoneme: str) -> str:
                        """PhÃ¢n loáº¡i phoneme: initial (phá»¥ Ã¢m Ä‘áº§u), vowel (nguyÃªn Ã¢m), final (phá»¥ Ã¢m cuá»‘i)"""
                        if phoneme in LEADS:
                            return "initial"  # Phá»¥ Ã¢m Ä‘áº§u
                        elif phoneme in VOWELS:
                            return "vowel"  # NguyÃªn Ã¢m
                        elif phoneme in TAILS:
                            return "final"  # Phá»¥ Ã¢m cuá»‘i
                        else:
                            return "other"
                    
                    # Táº¡o danh sÃ¡ch phoneme vá»›i thÃ´ng tin chi tiáº¿t
                    phoneme_details = []
                    
                    # Táº¡o map cá»§a wrong phonemes Ä‘á»ƒ dá»… tra cá»©u
                    wrong_phoneme_map = {}
                    for exp, pred in pronunciation_result.wrong_phonemes:
                        # TÃ¬m vá»‹ trÃ­ cá»§a wrong phoneme trong expected_phonemes
                        for idx, exp_phn in enumerate(pronunciation_result.expected_phonemes):
                            if exp_phn == exp and idx not in wrong_phoneme_map:
                                wrong_phoneme_map[idx] = pred
                                break
                    
                    # Xá»­ lÃ½ tá»«ng phoneme expected
                    max_len = max(len(pronunciation_result.expected_phonemes), len(pronunciation_result.predicted_phonemes))
                    for i in range(max_len):
                        exp_phn = pronunciation_result.expected_phonemes[i] if i < len(pronunciation_result.expected_phonemes) else None
                        pred_phn = pronunciation_result.predicted_phonemes[i] if i < len(pronunciation_result.predicted_phonemes) else None
                        
                        if exp_phn is None:
                            # Insertion - phoneme thá»«a
                            phoneme_details.append({
                                "position": i,
                                "expected": "",
                                "predicted": pred_phn,
                                "type": classify_phoneme(pred_phn) if pred_phn else "other",
                                "is_correct": False,
                                "is_extra": True
                            })
                        elif pred_phn is None:
                            # Deletion - phoneme thiáº¿u
                            phoneme_details.append({
                                "position": i,
                                "expected": exp_phn,
                                "predicted": "",
                                "type": classify_phoneme(exp_phn),
                                "is_correct": False,
                                "is_missing": True
                            })
                        else:
                            # So sÃ¡nh expected vs predicted
                            is_correct = exp_phn == pred_phn
                            # Náº¿u khÃ´ng Ä‘Ãºng, cÃ³ thá»ƒ lÃ  substitution
                            if not is_correct and i in wrong_phoneme_map:
                                pred_phn = wrong_phoneme_map[i]
                            
                            phoneme_details.append({
                                "position": i,
                                "expected": exp_phn,
                                "predicted": pred_phn,
                                "type": classify_phoneme(exp_phn),  # initial, vowel, final
                                "is_correct": is_correct
                            })
                    
                    # PhÃ¢n tÃ­ch tá»«ng tá»« vá»›i phoneme details
                    word_feedback_list = []
                    words = transcript.split()
                    
                    # Map phonemes to words (simplified - má»—i tá»« cÃ³ ~3 phonemes: initial, vowel, final)
                    phoneme_idx = 0
                    for word_idx, word in enumerate(words):
                        # Æ¯á»›c tÃ­nh sá»‘ phoneme trong tá»« nÃ y (má»—i kÃ½ tá»± Hangul = 2-3 phonemes)
                        word_phoneme_count = len(word) * 2  # Æ¯á»›c tÃ­nh
                        word_phonemes = []
                        
                        for i in range(min(word_phoneme_count, len(phoneme_details) - phoneme_idx)):
                            if phoneme_idx + i < len(phoneme_details):
                                phn_detail = phoneme_details[phoneme_idx + i]
                                word_phonemes.append(phn_detail)
                        
                        # TÃ­nh accuracy cho tá»« nÃ y
                        if word_phonemes:
                            correct_count = sum(1 for p in word_phonemes if p.get("is_correct", False))
                            word_accuracy = (correct_count / len(word_phonemes)) * 100
                        else:
                            word_accuracy = 0
                        
                        word_feedback_list.append({
                            "word": word,
                            "position": word_idx,
                            "phonemes": word_phonemes,
                            "accuracy": round(word_accuracy, 1),
                            "is_correct": word_accuracy >= 80  # Threshold 80%
                        })
                        
                        phoneme_idx += len(word_phonemes)
                    
                    # Táº¡o pháº£n há»“i chi tiáº¿t vá»›i phÃ¢n tÃ­ch tá»«ng phoneme
                    pronunciation_feedback = {
                        "phoneme_accuracy": pronunciation_result.phoneme_accuracy,
                        "per": pronunciation_result.per,
                        "phoneme_details": phoneme_details,  # Chi tiáº¿t tá»«ng phoneme vá»›i type (initial/vowel/final)
                        "word_feedback": word_feedback_list,  # Pháº£n há»“i tá»«ng tá»«
                        "wrong_phonemes": [
                            {
                                "expected": exp,
                                "predicted": pred,
                                "position": i,
                                "type": classify_phoneme(exp),  # initial, vowel, final
                                "is_correct": False,
                                "feedback": f"PhÃ¡t Ã¢m '{exp}' thÃ nh '{pred}'. Cáº§n luyá»‡n táº­p {'phá»¥ Ã¢m Ä‘áº§u' if classify_phoneme(exp) == 'initial' else 'nguyÃªn Ã¢m' if classify_phoneme(exp) == 'vowel' else 'phá»¥ Ã¢m cuá»‘i'}."
                            }
                            for i, (exp, pred) in enumerate(pronunciation_result.wrong_phonemes)
                        ],
                        "expected_phonemes": pronunciation_result.expected_phonemes,
                        "predicted_phonemes": pronunciation_result.predicted_phonemes,
                        "wrong_words": pronunciation_result.wrong_words,
                        "matches": pronunciation_result.matches,
                        "substitutions": pronunciation_result.substitutions,
                        "insertions": pronunciation_result.insertions,
                        "deletions": pronunciation_result.deletions,
                        "summary": {
                            "total_phonemes": len(pronunciation_result.expected_phonemes),
                            "correct_phonemes": pronunciation_result.matches,
                            "wrong_phonemes": pronunciation_result.substitutions,
                            "missing_phonemes": pronunciation_result.deletions,
                            "extra_phonemes": pronunciation_result.insertions,
                            "initial_errors": sum(1 for p in phoneme_details if p.get("type") == "initial" and not p.get("is_correct", True)),
                            "vowel_errors": sum(1 for p in phoneme_details if p.get("type") == "vowel" and not p.get("is_correct", True)),
                            "final_errors": sum(1 for p in phoneme_details if p.get("type") == "final" and not p.get("is_correct", True))
                        }
                    }
                    
                    logger.info(f"âœ… Pronunciation check: {pronunciation_accuracy:.1f}% accuracy, PER: {pronunciation_result.per:.4f}")
                    logger.info(f"   Wrong phonemes: {len(pronunciation_result.wrong_phonemes)}")
                else:
                    logger.warning("Pronunciation model check returned None")
            except Exception as e:
                logger.error(f"Error in pronunciation check: {e}. Continuing without pronunciation feedback.")

        # Step 4: Get conversational response from Coach Ivy (GPT)
        # GPT will respond in Korean like a real conversation
        # Include pronunciation feedback in context if available
        gpt_context = conversation_context or ({"type": "speaking_practice", "context": context} if context else None)
        if pronunciation_feedback:
            if gpt_context is None:
                gpt_context = {}
            gpt_context["pronunciation_feedback"] = {
                "accuracy": pronunciation_accuracy,
                "wrong_phonemes_count": len(pronunciation_feedback.get("wrong_phonemes", [])),
                "wrong_words": pronunciation_feedback.get("wrong_words", [])
            }
        
        reply, emotion_tag = await openai_service.chat_with_coach(
            message=transcript,
            mode="free_chat",
            context=gpt_context
        )
        
        # Log full reply for debugging
        logger.info(f"Coach Ivy replied (Korean, full): '{reply}'")
        logger.info(f"Coach Ivy replied (Korean, preview): '{reply[:100]}...'")
        logger.info(f"Reply length: {len(reply)} chars, emotion: {emotion_tag}")

        # Step 5: Generate TTS for Coach's response (Speech)
        # Coach responses are typically in Korean, so use "ko" language
        # Use allow_failure=True to gracefully handle TTS errors
        tts_path = await generate_speech(
            text=reply,
            lang="ko",  # Korean for Coach responses
            allow_failure=True  # Don't fail the whole request if TTS fails
        )
        
        tts_url = None
        if tts_path:
            tts_url = f"/media/{Path(tts_path).name}"
            logger.info(f"TTS generated: {tts_url}")
        else:
            logger.warning("TTS generation failed, but continuing with text response")

        # Return response with proper model
        response_data = FreeSpeakResponse(
            transcript=transcript,
            reply=reply,
            emotion_tag=emotion_tag,
            tts_url=tts_url,
            pronunciation_feedback=pronunciation_feedback,
            pronunciation_accuracy=pronunciation_accuracy
        )
        
        # Log response for debugging
        logger.info(f"Returning response - transcript: '{transcript}', reply: '{reply[:50]}...'")
        logger.info(f"   Pronunciation accuracy: {pronunciation_accuracy}%, tts_url: {tts_url}")
        
        return response_data

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in check_free_speaking: {e}")
        # Use error handler for OpenAI errors (429, etc.)
        raise handle_openai_error(e, service_name="Free speaking")
