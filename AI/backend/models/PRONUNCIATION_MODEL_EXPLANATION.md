# MÃ´ hÃ¬nh Pronunciation Model - Giáº£i thÃ­ch chi tiáº¿t

## ğŸ“‹ Tá»•ng quan

File `pronunciation_model.pt` (13MB) lÃ  má»™t **mÃ´ hÃ¬nh Deep Learning** Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ phÃ¡t Ã¢m tiáº¿ng HÃ n. ÄÃ¢y lÃ  má»™t mÃ´ hÃ¬nh **hybrid** káº¿t há»£p nhiá»u cÃ´ng nghá»‡ AI hiá»‡n Ä‘áº¡i.

## ğŸ—ï¸ Kiáº¿n trÃºc mÃ´ hÃ¬nh

### 1. **Wav2Vec2 (Facebook AI Research)**
- **Má»¥c Ä‘Ã­ch**: TrÃ­ch xuáº¥t features (Ä‘áº·c trÆ°ng) tá»« audio
- **Model**: `facebook/wav2vec2-base`
- **Input**: Audio waveform (16kHz, mono)
- **Output**: Feature vectors (768 dimensions)
- **Chá»©c nÄƒng**: Chuyá»ƒn Ä‘á»•i tÃ­n hiá»‡u Ã¢m thanh thÃ´ thÃ nh biá»ƒu diá»…n sá»‘ há»c cÃ³ Ã½ nghÄ©a

### 2. **Conformer Architecture** 
- **Má»¥c Ä‘Ã­ch**: Xá»­ lÃ½ vÃ  dá»± Ä‘oÃ¡n phonemes tá»« features
- **Kiáº¿n trÃºc**: 
  - **Input**: Wav2Vec2 features (768 dim) â†’ Projection (256 dim)
  - **Conformer Blocks** (3 layers):
    - **Feed-Forward Module**: Xá»­ lÃ½ thÃ´ng tin tuáº§n tá»±
    - **Multi-Head Self-Attention**: Náº¯m báº¯t dependencies dÃ i háº¡n
    - **Convolution Module**: Báº¯t local patterns
    - **Residual Connections**: GiÃºp training á»•n Ä‘á»‹nh
  - **Output**: Logits cho 55 phonemes tiáº¿ng HÃ n
- **Parameters**:
  - Input dimension: 768 (tá»« Wav2Vec2)
  - Hidden dimension: 256
  - Attention heads: 4
  - Depth: 3 Conformer blocks
  - Phoneme vocabulary: 55 phonemes

### 3. **CTC Decoding (Connectionist Temporal Classification)**
- **Má»¥c Ä‘Ã­ch**: Chuyá»ƒn Ä‘á»•i logits thÃ nh chuá»—i phonemes
- **PhÆ°Æ¡ng phÃ¡p**: Greedy decode (chá»n phoneme cÃ³ xÃ¡c suáº¥t cao nháº¥t)
- **Xá»­ lÃ½**: Loáº¡i bá» blank tokens vÃ  duplicate liÃªn tiáº¿p

## ğŸ“Š Quy trÃ¬nh hoáº¡t Ä‘á»™ng

```
Audio Input (16kHz)
    â†“
[Wav2Vec2 Feature Extraction]
    â†“
Feature Vectors (T, 768)
    â†“
[Normalization: mean/std]
    â†“
[Conformer Model]
    â†“
Logits (T, 55)
    â†“
[CTC Greedy Decode]
    â†“
Predicted Phonemes (ã„±, ã…, ã„´, ...)
    â†“
[Compare with Expected Phonemes]
    â†“
[Levenshtein Distance]
    â†“
Pronunciation Score & Feedback
```

## ğŸ“ CÃ¡c file liÃªn quan

### 1. `pronunciation_model.pt` (13MB)
- File chá»©a weights cá»§a Conformer model
- ÄÆ°á»£c train trÃªn dataset tiáº¿ng HÃ n
- Format: PyTorch state_dict

### 2. `p2id.json` (780B)
- **Phoneme-to-ID mapping**
- Map tá»«ng phoneme tiáº¿ng HÃ n sang ID sá»‘
- VÃ­ dá»¥:
  ```json
  {
    "<blank>": 0,
    "ã„±": 6,
    "ã…": 34,
    "ã„´": 9,
    ...
  }
  ```
- Tá»•ng cá»™ng: **55 phonemes** (bao gá»“m cÃ¡c phá»¥ Ã¢m, nguyÃªn Ã¢m, vÃ  kÃ½ tá»± Ä‘áº·c biá»‡t)

### 3. `wav2vec2_stats.npy` (136B)
- **Normalization statistics**
- Chá»©a mean vÃ  std Ä‘á»ƒ normalize Wav2Vec2 features
- Äáº£m báº£o features cÃ³ distribution phÃ¹ há»£p vá»›i model Ä‘Ã£ train

### 4. `korean_phrases.json` (6.6KB)
- Danh sÃ¡ch cÃ¡c cÃ¢u/phrase tiáº¿ng HÃ n máº«u
- DÃ¹ng cho pronunciation practice
- 289 entries

## ğŸ¯ CÃ´ng dá»¥ng chÃ­nh

### 1. **Pronunciation Assessment (ÄÃ¡nh giÃ¡ phÃ¡t Ã¢m)**
- So sÃ¡nh phÃ¡t Ã¢m cá»§a ngÆ°á»i dÃ¹ng vá»›i phÃ¡t Ã¢m chuáº©n
- TÃ­nh Ä‘á»™ chÃ­nh xÃ¡c á»Ÿ má»©c **phoneme level**
- PhÃ¡t hiá»‡n lá»—i phÃ¡t Ã¢m chi tiáº¿t (initial, vowel, final consonants)

### 2. **Detailed Feedback**
- Chá»‰ ra tá»«ng phoneme nÃ o Ä‘Ãºng/sai
- PhÃ¢n loáº¡i lá»—i (substitution, insertion, deletion)
- TÃ­nh accuracy cho tá»«ng tá»« vÃ  toÃ n cÃ¢u

### 3. **Real-time Processing**
- Xá»­ lÃ½ audio trong vÃ i giÃ¢y
- KhÃ´ng cáº§n GPU (cÃ³ thá»ƒ cháº¡y trÃªn CPU)
- Optimized cho inference speed

## ğŸ”§ CÃ´ng nghá»‡ sá»­ dá»¥ng

### Deep Learning Frameworks
- **PyTorch**: Framework chÃ­nh cho training vÃ  inference
- **Transformers** (Hugging Face): Load Wav2Vec2 pre-trained model
- **Librosa**: Xá»­ lÃ½ audio (resample, normalize)

### Algorithms
- **CTC Loss**: Training strategy Ä‘á»ƒ align audio vá»›i phonemes
- **Levenshtein Distance**: TÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a sequences
- **Greedy Decoding**: Chuyá»ƒn Ä‘á»•i logits â†’ phonemes

## ğŸ“ˆ Model Performance

- **Input**: Audio file (webm, mp3, wav, m4a)
- **Output**: 
  - Predicted phonemes
  - Accuracy score (0-100%)
  - Detailed feedback (word-level, phoneme-level)
- **Processing time**: ~2-5 giÃ¢y/cÃ¢u (tÃ¹y Ä‘á»™ dÃ i audio)

## ğŸ“ Training Process

Model nÃ y Ä‘Æ°á»£c train trÃªn:
- **Dataset**: Korean pronunciation dataset
- **Objective**: Minimize CTC loss giá»¯a predicted vÃ  expected phonemes
- **Features**: Sá»­ dá»¥ng Wav2Vec2 pre-trained features (transfer learning)
- **Fine-tuning**: Conformer layers Ä‘Æ°á»£c fine-tune cho tiáº¿ng HÃ n

## ğŸ” So sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c

| PhÆ°Æ¡ng phÃ¡p | Æ¯u Ä‘iá»ƒm | NhÆ°á»£c Ä‘iá»ƒm |
|------------|---------|-----------|
| **Rule-based** | Nhanh, khÃ´ng cáº§n model | KhÃ´ng chÃ­nh xÃ¡c, khÃ´ng linh hoáº¡t |
| **Traditional ML** | ÄÆ¡n giáº£n | Cáº§n nhiá»u feature engineering |
| **Deep Learning (Conformer)** âœ… | ChÃ­nh xÃ¡c cao, tá»± Ä‘á»™ng há»c features | Cáº§n GPU Ä‘á»ƒ train, model lá»›n hÆ¡n |

## ğŸ’¡ LÃ½ do chá»n Conformer

1. **Self-Attention**: Náº¯m báº¯t dependencies dÃ i háº¡n trong audio
2. **Convolution**: Báº¯t local patterns (phá»¥ Ã¢m, nguyÃªn Ã¢m)
3. **Efficiency**: CÃ¢n báº±ng tá»‘t giá»¯a accuracy vÃ  speed
4. **Proven**: ÄÆ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong speech recognition (Google, Meta)

## ğŸ”— TÃ i liá»‡u tham kháº£o

- **Wav2Vec2**: [Facebook AI Research](https://github.com/facebookresearch/fairseq)
- **Conformer**: [Google Research - Conformer Paper](https://arxiv.org/abs/2005.08100)
- **CTC**: [Connectionist Temporal Classification](https://distill.pub/2017/ctc/)

## ğŸ“ LÆ°u Ã½

- Model nÃ y Ä‘Æ°á»£c train **offline** vÃ  load vÃ o memory khi server khá»Ÿi Ä‘á»™ng
- Cáº§n ~1-2GB RAM Ä‘á»ƒ load model vÃ  Wav2Vec2
- CÃ³ thá»ƒ cháº¡y trÃªn CPU nhÆ°ng GPU sáº½ nhanh hÆ¡n Ä‘Ã¡ng ká»ƒ
- Model chá»‰ há»— trá»£ tiáº¿ng HÃ n (Korean phonemes)

